{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "gL4uegs26WHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqfjXb4Y60iq"
      },
      "outputs": [],
      "source": [
        "from dense import Dense\n",
        "from convolutional import Convolutional\n",
        "from reshape import Reshape\n",
        "from activations import Softmax, Sigmoid\n",
        "from losses import binary_cross_entropy, binary_cross_entropy_prime, categorical_cross_entropy,  categorical_cross_entropy_prime\n",
        "from networks import train, predict\n",
        "from activation import Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms4ininpMhnr"
      },
      "outputs": [],
      "source": [
        "class LeakyReLU(Activation):\n",
        "    def __init__(self, alpha):\n",
        "        def leaky_relu(x):\n",
        "            return np.where(x > 0, x, alpha * x)\n",
        "\n",
        "        def leaky_relu_prime(x):\n",
        "            return np.where(x > 0, 1, alpha)\n",
        "\n",
        "        super().__init__(leaky_relu, leaky_relu_prime)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-inB1T6c_s2X"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(x, y, limit=None):\n",
        "    # Shuffle dataset\n",
        "    indices = np.arange(len(x))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    if limit:\n",
        "        indices = indices[:limit]\n",
        "\n",
        "    x, y = x[indices], y[indices]\n",
        "\n",
        "    # Reshape to match (channels, height, width)\n",
        "    x = x.reshape(len(x), 1, 28, 28)\n",
        "    x = x.astype(\"float32\") / 255\n",
        "\n",
        "    # One-hot encode labels (0-9 â†’ 10 classes)\n",
        "    y = to_categorical(y, num_classes=10)\n",
        "    y = y.reshape(len(y), 10, 1)\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-_fsYqjCWEF"
      },
      "outputs": [],
      "source": [
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Example: take all data\n",
        "x_train, y_train = preprocess_data(x_train, y_train, 15000)\n",
        "x_test, y_test = preprocess_data(x_test, y_test, 800)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu1uooTI6hmr",
        "outputId": "f1763b5e-4c0c-438e-d8f1-5f3d37674f5a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.65882355,\n",
              "         1.        , 0.32156864, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.46666667, 0.9882353 ,\n",
              "         0.99607843, 0.7921569 , 0.26666668, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.02745098, 0.8039216 , 0.99607843,\n",
              "         0.99607843, 0.99607843, 0.9490196 , 0.2901961 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.6745098 , 0.99607843, 0.5803922 ,\n",
              "         0.01568628, 0.45882353, 0.99607843, 0.9490196 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.10196079, 0.90588236, 0.99607843, 0.25490198,\n",
              "         0.        , 0.04705882, 0.93333334, 0.95686275, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.6039216 , 0.99607843, 0.63529414, 0.01568628,\n",
              "         0.        , 0.        , 0.92156863, 0.95686275, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.9607843 , 0.99607843, 0.3019608 , 0.        ,\n",
              "         0.        , 0.37254903, 0.8901961 , 0.39607844, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.9607843 , 0.99607843, 0.3019608 , 0.        ,\n",
              "         0.2509804 , 0.9411765 , 0.8235294 , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.8392157 , 0.99607843, 0.78431374, 0.69803923,\n",
              "         0.9372549 , 0.99607843, 0.7019608 , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.10980392, 0.827451  , 0.99607843, 0.99607843,\n",
              "         0.99607843, 0.7647059 , 0.03921569, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.08627451, 0.60784316, 0.99607843,\n",
              "         0.99607843, 0.99607843, 0.6862745 , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.02352941, 0.7882353 , 0.7529412 ,\n",
              "         0.31764707, 0.6627451 , 0.9411765 , 0.14117648, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.28627452, 0.99607843, 0.22352941,\n",
              "         0.        , 0.3019608 , 0.99607843, 0.5529412 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.7529412 , 0.5803922 , 0.01176471,\n",
              "         0.        , 0.0627451 , 0.9372549 , 0.5803922 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.24705882, 0.9372549 , 0.3019608 , 0.        ,\n",
              "         0.        , 0.        , 0.92156863, 0.5803922 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.9254902 , 0.9529412 , 0.14117648, 0.        ,\n",
              "         0.        , 0.16078432, 0.9607843 , 0.5803922 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.13725491, 0.972549  , 0.627451  , 0.        , 0.        ,\n",
              "         0.01176471, 0.6       , 0.99215686, 0.28627452, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.2509804 , 0.9843137 , 0.8039216 , 0.08235294, 0.15294118,\n",
              "         0.5803922 , 0.99607843, 0.7254902 , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.9098039 , 0.99607843, 0.91764706, 0.94509804,\n",
              "         0.99607843, 0.7882353 , 0.07843138, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.14509805, 0.58431375, 0.99607843, 0.99607843,\n",
              "         0.52156866, 0.07843138, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "    Convolutional((1, 28, 28), 3, 3),\n",
        "    LeakyReLU(0.01),\n",
        "    Convolutional((3, 26, 26), 3, 3),\n",
        "    LeakyReLU(0.01),\n",
        "    Reshape((3, 24, 24), (3 * 24 * 24, 1)),\n",
        "    Dense(3 * 24 * 24, 100),\n",
        "    LeakyReLU(0.01),\n",
        "    Dense(100, 10), # Changed output size to 10 to match the number of classes\n",
        "    Softmax()\n",
        "    # dense ip 50 reduced accuracy #retry with dense 100 but two conv layers\n",
        "]"
      ],
      "metadata": {
        "id": "YeubvgGMEF3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "    Convolutional((1, 28, 28), 3, 3),\n",
        "    Sigmoid(),\n",
        "    Convolutional((3, 26, 26), 3, 3),\n",
        "    Sigmoid(),\n",
        "    Reshape((3, 24, 24), (3 * 24 * 24, 1)),\n",
        "    Dense(3 * 24 * 24, 100),\n",
        "    Sigmoid(),\n",
        "    Dense(100, 100),\n",
        "    Sigmoid(),\n",
        "    Dense(100, 10), # Changed output size to 10 to match the number of classes\n",
        "    Softmax()\n",
        "    # dense ip 50 reduced accuracy #retry with dense 100 but two conv layers\n",
        "]\n",
        "#best one so far wrt error but laned on 94 ish percent accuracy"
      ],
      "metadata": {
        "id": "K3Wcue8Mf8En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "    Convolutional((1, 28, 28), 3, 3),\n",
        "    Sigmoid(),\n",
        "    Convolutional((3, 26, 26), 3, 3),\n",
        "    Sigmoid(),\n",
        "    Reshape((3, 24, 24), (3 * 24 * 24, 1)),\n",
        "    Dense(3 * 24 * 24, 100),\n",
        "    Sigmoid(),\n",
        "    Dense(100, 10), # Changed output size to 10 to match the number of classes\n",
        "    Softmax()\n",
        "    # dense ip 50 reduced accuracy #retry with dense 100 but two conv layers\n",
        "]\n",
        "#95.62 latest"
      ],
      "metadata": {
        "id": "ZPki2F7opikF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZIv3gSW44uM"
      },
      "outputs": [],
      "source": [
        "network = [\n",
        "    Convolutional((1, 28, 28), 3, 3),\n",
        "    Sigmoid(),\n",
        "    Reshape((3, 26, 26), (3 * 26 * 26, 1)),\n",
        "    Dense(3 * 26 * 26, 100),\n",
        "    Sigmoid(),\n",
        "    Dense(100, 10), # Changed output size to 10 to match the number of classes\n",
        "    Softmax()\n",
        "]\n",
        "# 95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5X8vzQ5XOL_"
      },
      "source": [
        "8 layers 2000 data set, 90+ accuracy\n",
        "\n",
        "7 layers 4000 data set, 90.62 accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFaUS8UmDsQ_",
        "collapsed": true,
        "outputId": "8b4f0a32-99fc-4c29-94da-ca7bf0dbfa6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/50, error=0.03525826981080664\n",
            "2/50, error=0.012389614394047581\n",
            "3/50, error=0.007102000390671742\n",
            "4/50, error=0.005086337878900215\n",
            "5/50, error=0.004101361164373569\n",
            "6/50, error=0.0031197296309516814\n",
            "7/50, error=0.002842463476631632\n",
            "8/50, error=0.002351970883126922\n",
            "9/50, error=0.001870116885465538\n",
            "10/50, error=0.00260223899260868\n",
            "11/50, error=0.0017335708643255248\n",
            "12/50, error=0.001620031982334359\n",
            "13/50, error=0.0013551419940261082\n",
            "14/50, error=0.0012665619855197385\n",
            "15/50, error=0.0016389022761904598\n",
            "16/50, error=0.0015336711037185818\n",
            "17/50, error=0.002646492665995849\n",
            "18/50, error=0.0013899170343955433\n",
            "19/50, error=0.0012911460716370745\n",
            "20/50, error=0.0013569576284565817\n",
            "21/50, error=0.0029313829665525855\n",
            "22/50, error=0.0008880198482115007\n",
            "23/50, error=0.0005372149721691418\n",
            "24/50, error=0.0016060330152036894\n",
            "25/50, error=0.0011687383106212068\n",
            "26/50, error=0.0007540576224342432\n",
            "27/50, error=0.0011151596832846378\n",
            "28/50, error=0.0012858882620413261\n",
            "29/50, error=0.0012464570501406432\n",
            "30/50, error=7.488209004819398e-05\n",
            "31/50, error=2.7307142411993592e-06\n",
            "32/50, error=1.1394250083565229e-06\n",
            "33/50, error=9.316026517521415e-07\n",
            "34/50, error=7.987875275533899e-07\n",
            "35/50, error=7.036893664422553e-07\n",
            "36/50, error=6.309147741488753e-07\n",
            "37/50, error=5.729912566940852e-07\n",
            "38/50, error=5.25356989163271e-07\n",
            "39/50, error=4.854461793356156e-07\n",
            "40/50, error=4.513882284563366e-07\n",
            "41/50, error=4.217128353336323e-07\n",
            "42/50, error=3.957726184095136e-07\n",
            "43/50, error=3.728675165231289e-07\n",
            "44/50, error=3.52559796362265e-07\n",
            "45/50, error=3.34461157477379e-07\n",
            "46/50, error=3.1817818536996487e-07\n",
            "47/50, error=3.034324580978063e-07\n",
            "48/50, error=2.900810487473437e-07\n",
            "49/50, error=2.778808835171482e-07\n",
            "50/50, error=2.666905349966335e-07\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "train(\n",
        "    network,\n",
        "    categorical_cross_entropy,\n",
        "    categorical_cross_entropy_prime,\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    learning_rate=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LGs2N8XZDzNb",
        "outputId": "907f7339-3172-4625-e696-536fc5364e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred: 0, true: 0\n",
            "pred: 3, true: 3\n",
            "pred: 0, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 9, true: 7\n",
            "pred: 0, true: 0\n",
            "pred: 5, true: 5\n",
            "pred: 7, true: 7\n",
            "pred: 2, true: 2\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 2, true: 2\n",
            "pred: 3, true: 3\n",
            "pred: 4, true: 4\n",
            "pred: 1, true: 8\n",
            "pred: 3, true: 3\n",
            "pred: 0, true: 0\n",
            "pred: 6, true: 6\n",
            "pred: 0, true: 0\n",
            "pred: 6, true: 6\n",
            "pred: 3, true: 3\n",
            "pred: 6, true: 6\n",
            "pred: 2, true: 2\n",
            "pred: 9, true: 9\n",
            "pred: 8, true: 8\n",
            "pred: 6, true: 6\n",
            "pred: 9, true: 9\n",
            "pred: 3, true: 3\n",
            "pred: 7, true: 7\n",
            "pred: 3, true: 3\n",
            "pred: 0, true: 0\n",
            "pred: 7, true: 7\n",
            "pred: 9, true: 9\n",
            "pred: 7, true: 7\n",
            "pred: 9, true: 9\n",
            "pred: 9, true: 9\n",
            "pred: 3, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 9, true: 9\n",
            "pred: 2, true: 2\n",
            "pred: 2, true: 2\n",
            "pred: 1, true: 1\n",
            "pred: 5, true: 5\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 0, true: 0\n",
            "pred: 6, true: 2\n",
            "pred: 5, true: 5\n",
            "pred: 9, true: 9\n",
            "pred: 8, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 4, true: 4\n",
            "pred: 9, true: 9\n",
            "pred: 7, true: 7\n",
            "pred: 0, true: 0\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 8, true: 0\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 7, true: 7\n",
            "pred: 0, true: 0\n",
            "pred: 3, true: 3\n",
            "pred: 0, true: 0\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 4\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 0, true: 0\n",
            "pred: 3, true: 3\n",
            "pred: 2, true: 2\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 3, true: 3\n",
            "pred: 7, true: 7\n",
            "pred: 0, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 5, true: 5\n",
            "pred: 7, true: 9\n",
            "pred: 8, true: 8\n",
            "pred: 6, true: 2\n",
            "pred: 0, true: 0\n",
            "pred: 5, true: 5\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 4, true: 4\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 3, true: 3\n",
            "pred: 2, true: 2\n",
            "pred: 3, true: 3\n",
            "pred: 4, true: 4\n",
            "pred: 0, true: 0\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 4, true: 2\n",
            "pred: 9, true: 9\n",
            "pred: 2, true: 2\n",
            "pred: 3, true: 3\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 4, true: 4\n",
            "pred: 8, true: 8\n",
            "pred: 7, true: 4\n",
            "pred: 0, true: 0\n",
            "pred: 7, true: 7\n",
            "pred: 2, true: 2\n",
            "pred: 5, true: 5\n",
            "pred: 2, true: 2\n",
            "pred: 8, true: 8\n",
            "pred: 7, true: 7\n",
            "pred: 5, true: 5\n",
            "pred: 6, true: 6\n",
            "pred: 1, true: 1\n",
            "pred: 7, true: 7\n",
            "pred: 1, true: 1\n",
            "pred: 8, true: 8\n",
            "pred: 8, true: 5\n",
            "pred: 5, true: 5\n",
            "pred: 9, true: 9\n",
            "pred: 0, true: 0\n",
            "pred: 9, true: 9\n",
            "pred: 5, true: 5\n",
            "pred: 9, true: 9\n",
            "pred: 8, true: 8\n",
            "pred: 2, true: 2\n",
            "pred: 5, true: 5\n",
            "pred: 6, true: 6\n",
            "pred: 2, true: 2\n",
            "pred: 7, true: 7\n",
            "pred: 6, true: 6\n",
            "pred: 1, true: 1\n",
            "pred: 9, true: 9\n",
            "pred: 7, true: 7\n",
            "pred: 1, true: 1\n",
            "pred: 9, true: 9\n",
            "pred: 7, true: 7\n",
            "pred: 5, true: 5\n",
            "pred: 8, true: 8\n",
            "pred: 8, true: 8\n",
            "pred: 7, true: 5\n",
            "pred: 5, true: 5\n",
            "pred: 3, true: 3\n",
            "pred: 5, true: 9\n",
            "pred: 1, true: 1\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 8, true: 8\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 3, true: 3\n",
            "pred: 9, true: 9\n",
            "pred: 6, true: 6\n",
            "pred: 2, true: 2\n",
            "pred: 5, true: 5\n",
            "pred: 2, true: 2\n",
            "pred: 7, true: 7\n",
            "pred: 0, true: 0\n",
            "pred: 7, true: 7\n",
            "pred: 5, true: 5\n",
            "pred: 0, true: 0\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 8, true: 8\n",
            "pred: 9, true: 9\n",
            "pred: 2, true: 2\n",
            "pred: 3, true: 3\n",
            "pred: 5, true: 5\n",
            "pred: 7, true: 7\n",
            "pred: 9, true: 9\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 0, true: 0\n",
            "pred: 0, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 7, true: 7\n",
            "pred: 4, true: 4\n",
            "pred: 9, true: 9\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 3, true: 3\n",
            "pred: 5, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 7, true: 7\n",
            "pred: 9, true: 9\n",
            "pred: 8, true: 2\n",
            "pred: 5, true: 5\n",
            "pred: 7, true: 7\n",
            "pred: 7, true: 7\n",
            "pred: 6, true: 6\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 6\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 7, true: 9\n",
            "pred: 9, true: 9\n",
            "pred: 4, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 0, true: 0\n",
            "pred: 2, true: 2\n",
            "pred: 9, true: 9\n",
            "pred: 1, true: 1\n",
            "pred: 0, true: 0\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 9, true: 9\n",
            "pred: 2, true: 2\n",
            "pred: 5, true: 5\n",
            "pred: 8, true: 8\n",
            "pred: 1, true: 1\n",
            "pred: 9, true: 9\n",
            "pred: 5, true: 5\n",
            "pred: 5, true: 5\n",
            "pred: 3, true: 3\n",
            "pred: 5, true: 5\n",
            "pred: 7, true: 7\n",
            "pred: 7, true: 7\n",
            "pred: 6, true: 6\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 4, true: 4\n",
            "pred: 7, true: 7\n",
            "pred: 8, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 2, true: 2\n",
            "pred: 0, true: 0\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 3, true: 3\n",
            "pred: 2, true: 2\n",
            "pred: 9, true: 4\n",
            "pred: 2, true: 2\n",
            "pred: 8, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 6, true: 6\n",
            "pred: 1, true: 1\n",
            "pred: 0, true: 0\n",
            "pred: 7, true: 7\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 8, true: 8\n",
            "pred: 6, true: 4\n",
            "pred: 8, true: 8\n",
            "pred: 1, true: 7\n",
            "pred: 9, true: 9\n",
            "pred: 4, true: 4\n",
            "pred: 5, true: 9\n",
            "pred: 1, true: 1\n",
            "pred: 2, true: 2\n",
            "pred: 0, true: 0\n",
            "pred: 4, true: 9\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 2, true: 7\n",
            "pred: 8, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 8, true: 8\n",
            "pred: 9, true: 9\n",
            "pred: 8, true: 8\n",
            "pred: 4, true: 4\n",
            "pred: 4, true: 4\n",
            "pred: 2, true: 2\n",
            "pred: 1, true: 1\n",
            "pred: 5, true: 5\n",
            "pred: 4, true: 4\n",
            "pred: 6, true: 6\n",
            "pred: 0, true: 0\n",
            "pred: 3, true: 3\n",
            "pred: 5, true: 5\n",
            "pred: 0, true: 0\n",
            "pred: 6, true: 6\n",
            "pred: 7, true: 7\n",
            "pred: 3, true: 3\n",
            "pred: 8, true: 2\n",
            "pred: 2, true: 2\n",
            "pred: 8, true: 8\n",
            "pred: 4, true: 4\n",
            "pred: 9, true: 9\n",
            "pred: 2, true: 2\n",
            "pred: 1, true: 1\n",
            "pred: 6, true: 6\n",
            "pred: 2, true: 2\n",
            "pred: 8, true: 3\n",
            "pred: 9, true: 9\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 4, true: 4\n",
            "pred: 1, true: 8\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 4, true: 4\n",
            "pred: 5, true: 5\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 5, true: 5\n",
            "pred: 9, true: 9\n",
            "pred: 4, true: 9\n",
            "pred: 5, true: 5\n",
            "pred: 7, true: 7\n",
            "pred: 2, true: 2\n",
            "pred: 7, true: 7\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 3, true: 3\n",
            "pred: 8, true: 8\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 4\n",
            "pred: 2, true: 2\n",
            "pred: 0, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 5, true: 5\n",
            "pred: 2, true: 2\n",
            "pred: 3, true: 3\n",
            "pred: 8, true: 8\n",
            "pred: 2, true: 2\n",
            "pred: 1, true: 1\n",
            "pred: 8, true: 8\n",
            "pred: 3, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 6, true: 6\n",
            "pred: 4, true: 9\n",
            "pred: 2, true: 2\n",
            "pred: 3, true: 7\n",
            "pred: 4, true: 4\n",
            "pred: 3, true: 3\n",
            "pred: 2, true: 2\n",
            "pred: 7, true: 7\n",
            "pred: 3, true: 3\n",
            "pred: 7, true: 7\n",
            "pred: 6, true: 6\n",
            "pred: 9, true: 9\n",
            "pred: 5, true: 5\n",
            "pred: 5, true: 5\n",
            "pred: 4, true: 4\n",
            "pred: 5, true: 5\n",
            "pred: 1, true: 1\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 5\n",
            "pred: 0, true: 5\n",
            "pred: 3, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 8, true: 8\n",
            "pred: 0, true: 2\n",
            "pred: 0, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 3, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 4, true: 4\n",
            "pred: 5, true: 5\n",
            "pred: 1, true: 1\n",
            "pred: 6, true: 6\n",
            "pred: 7, true: 9\n",
            "pred: 8, true: 3\n",
            "pred: 0, true: 0\n",
            "pred: 5, true: 5\n",
            "pred: 3, true: 3\n",
            "pred: 7, true: 7\n",
            "pred: 9, true: 9\n",
            "pred: 0, true: 0\n",
            "pred: 7, true: 7\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 0, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 8, true: 5\n",
            "pred: 3, true: 8\n",
            "pred: 0, true: 0\n",
            "pred: 4, true: 4\n",
            "pred: 7, true: 7\n",
            "pred: 2, true: 2\n",
            "pred: 6, true: 6\n",
            "pred: 9, true: 9\n",
            "pred: 1, true: 1\n",
            "pred: 6, true: 6\n",
            "pred: 6, true: 6\n",
            "pred: 7, true: 3\n"
          ]
        }
      ],
      "source": [
        "# test\n",
        "for x, y in zip(x_test, y_test):\n",
        "    output = predict(network, x)\n",
        "    print(f\"pred: {np.argmax(output)}, true: {np.argmax(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP99fAj5FTIi",
        "outputId": "1f80903f-5b2e-49e0-b50b-93adfafa2878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.88%\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = len(x_test)\n",
        "\n",
        "for x, y in zip(x_test, y_test):\n",
        "    output = predict(network, x)\n",
        "    if np.argmax(output) == np.argmax(y):\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy3WLRWcQ3jS"
      },
      "outputs": [],
      "source": [
        "def get_all_params(network):\n",
        "    params = []\n",
        "    for i, layer in enumerate(network):\n",
        "        layer_info = {\"layer_index\": i, \"type\": type(layer).__name__}\n",
        "        if hasattr(layer, \"kernels\"):\n",
        "            layer_info[\"kernels\"] = layer.kernels\n",
        "            layer_info[\"biases\"] = layer.biases\n",
        "        elif hasattr(layer, \"weights\"):\n",
        "            layer_info[\"weights\"] = layer.weights\n",
        "            layer_info[\"bias\"] = layer.bias\n",
        "        params.append(layer_info)\n",
        "    return params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRFq-DqQ8oMe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}